
!obj:pylearn2.train.Train {
    dataset: &train !obj:keypoint_Dataset.KeypointDataset {
        which_set: 'train',
        keypointNumber: {0},
        start: 0.0,
        stop: 0.90,
        preprocessor: !obj:pylearn2.datasets.preprocessing.Standardize {},
        fit_preprocessor: True,
        fit_test_preprocessor: True,
    },

    model: !obj:pylearn2.models.mlp.MLP {
        batch_size: 100,
        input_space: !obj:pylearn2.space.Conv2DSpace {
            shape: [48, 48],
            num_channels: 1
        },
        layers: [ !obj:pylearn2.models.mlp.ConvRectifiedLinear {
                     layer_name: 'h0',
                     output_channels: 32,
                     irange: .05,
                     kernel_shape: [5, 5],
                     pool_shape: [4, 4],
                     pool_stride: [3, 3],
                     max_kernel_norm: 1.9365,
                 },
                 !obj:pylearn2.models.mlp.ConvRectifiedLinear {
                     layer_name: 'h1',
                     output_channels: 32,
                     irange: .05,
                     kernel_shape: [5, 5],
                     pool_shape: [4, 4],
                     pool_stride: [3, 3],
                     max_kernel_norm: 1.9365,
                 },
                 !obj:pylearn2.models.mlp.Tanh {
                     layer_name: 'h2',
                     dim: 100,
                     sparse_init: 15
                 },
                 !obj:pylearn2.models.mlp.Linear {
                     layer_name: 'y',
                     dim: 2,
                     sparse_init: 5
                 }
                ],
    },

    # We use SGD as our training algorithm
    algorithm: !obj:pylearn2.training_algorithms.bgd.BGD {
        #batch_size: 100,
        #learning_rate: 0.001,
        # What we monitor
        line_search_mode: 'exhaustive',
        monitoring_dataset:
            {
                'train' : *train ,
                'valid' : !obj:keypoint_Dataset.KeypointDataset {
                              which_set: 'train',
                              keypointNumber: {0},
                              start: 0.70, # Keep the last 500 exemples as validation set
                              stop: 1.0,
                              preprocessor: !obj:pylearn2.datasets.preprocessing.Standardize {},
                              fit_preprocessor: True,
                              fit_test_preprocessor: True,
                          }
                # We don't have labels for the public test set
            },
        # The cost function is
        cost: !obj:pylearn2.costs.mlp.missing_target_cost.MissingTargetCost {
        },
        # The termination criteria
        termination_criterion: !obj:pylearn2.termination_criteria.MonitorBased {
            channel_name: "valid_objective"
        }
    },
    extensions: [
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
             channel_name: 'valid_objective',
             save_path: "{1}/generic_keypoint_{0}.pkl"
        },
    ]
}